|    | Size   | Mode                 |   d_model |   d_ff |   num_layers |   num_heads |   Context_length |   Avg Time (s) |   Std Dev (s) |   Warmup Steps |
|---:|:-------|:---------------------|----------:|-------:|-------------:|------------:|-----------------:|---------------:|--------------:|---------------:|
|  0 | small  | forward              |       768 |   3072 |           12 |          12 |              256 |       0.013145 |      0.000108 |              5 |
|  1 | small  | forward_and_backward |       768 |   3072 |           12 |          12 |              256 |       0.043638 |      0.001201 |              5 |
|  2 | medium | forward              |      1024 |   4096 |           24 |          16 |              256 |       0.027589 |      0.002537 |              5 |
|  3 | medium | forward_and_backward |      1024 |   4096 |           24 |          16 |              256 |       0.096616 |      0.005559 |              5 |
|  4 | lagre  | forward              |      1280 |   5120 |           36 |          20 |              256 |       0.041004 |      0.001884 |              5 |
|  5 | lagre  | forward_and_backward |      1280 |   5120 |           36 |          20 |              256 |       0.16254  |      0.012549 |              5 |
|  6 | xl     | forward              |      1600 |   6400 |           48 |          25 |              256 |       0.060339 |      0.003017 |              5 |
|  7 | xl     | forward_and_backward |      1600 |   6400 |           48 |          25 |              256 |       0.268257 |      0.029775 |              5 |
|  8 | 2.7B   | forward              |      2560 |  10240 |           32 |          32 |              256 |       0.072765 |      0.001698 |              5 |
|  9 | 2.7B   | forward_and_backward |      2560 |  10240 |           32 |          32 |              256 |       0.386593 |      0.031662 |              5 |

### 1. 耗时比例：反向传播是前向传播的 ~3-4 倍

从数据中可以观察到，`forward_and_backward` 的总时间大约是单纯 `forward` 时间的 **3 到 4 倍**。

- **理论依据**：在数学上，反向传播（Backward Pass）通常涉及两次矩阵乘法（一次针对梯度的计算，一次针对权重的计算），而前向传播只有一次。
- **实际表现**：由于反向传播还需要进行额外的内存操作（存储中间变量用于梯度计算），因此总耗时通常落在前向传播的 3 倍左右。例如，Small 模型前向 13ms，总共 43ms，比例约为 3.3x。

### 2. 算力与模型规模的线性关系

随着模型从 **Small (768d)** 扩展到 **2.7B (2560d)**，耗时呈现出明显的增长趋势：

- **参数量与深度**：层数（num_layers）从 12 增加到 32，宽度（d_model）从 768 增加到 2560。
- **计算效率**：尽管模型规模增加了许多倍，但前向传播时间仅从 13ms 增加到 72ms。这说明大型矩阵乘法在 A100/H100 等高端 GPU 上具有极高的利用率（计算密集型任务比小模型更“划算”）。

### 3. 稳定性与方差（Std Dev）

- **小模型非常稳定**：Small 和 Medium 模型的标准差（Std Dev）极低，说明 GPU 调度非常均匀。
- **大模型波动增加**：随着模型变大（特别是 **xl** 和 **2.7B**），标准差开始上升（从 0.0001s 升至 0.03s）。
  - **原因**：这通常是因为大模型触及了显存带宽的瓶颈，或者在进行大宗数据交换时受到了 GPU 频率波动（Power Throttling）或复杂的 CUDA Kernel 调度影响。

### 4. 显存瓶颈的信号

观察 **2.7B** 模型，其反向传播的标准差显著增大（~31ms）。这通常意味着此时 GPU 的显存压力很大，或者在进行梯度累加时出现了更多的缓存未命中（Cache Misses）。